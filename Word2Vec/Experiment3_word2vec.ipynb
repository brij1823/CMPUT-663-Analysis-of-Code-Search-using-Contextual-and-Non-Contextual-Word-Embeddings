{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8f46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprting Libraries\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import astor\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# #pip install nmslib\n",
    "#import nmslib\n",
    "import numpy\n",
    "import re\n",
    "#python -m spacy download en_core_web_sm\n",
    "EN = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d493015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the dataset\n",
    "# ! wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
    "# ! unzip python.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b74e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and Parsing data from database\n",
    "path = Path('.')\n",
    "#collapse_show\n",
    "def jsonl_list_to_dataframe(file_list, columns=None):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f,\n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "\n",
    "def get_dfs(path):\n",
    "    \"\"\"Grabs the different data splits and converts them into dataframes\"\"\"\n",
    "    dfs = []\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        files = sorted((path/split).glob(\"**/*.gz\"))\n",
    "        df = jsonl_list_to_dataframe(files, [\"code\", \"docstring\",\"code_tokens\",\"docstring_tokens\",\"url\"])\n",
    "        dfs.append(df)\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "\n",
    "def tokenize_docstring(text):\n",
    "    \"Apply tokenization using spacy to docstrings.\"\n",
    "    tokens = EN.tokenizer(text)\n",
    "    return [token.text.lower() for token in tokens if not token.is_space]\n",
    "\n",
    "\n",
    "def tokenize_code(text):\n",
    "    \"A very basic procedure for tokenizing code strings.\"\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "\n",
    "df_trn, df_val, df_tst = get_dfs(path/\"python/final/jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5c2f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5)\n"
     ]
    }
   ],
   "source": [
    "#Subsampling the original database\n",
    "df_trn_sub = df_trn[:5000]\n",
    "print(df_trn_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb95e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstring = list(df_trn_sub['docstring'].values)\n",
    "code = list(df_trn_sub['code'].values)\n",
    "#print(code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0739072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:07, 685.75it/s] \n"
     ]
    }
   ],
   "source": [
    "codeToken = []\n",
    "docToken = []\n",
    "\n",
    "for singleCode,singleDoc in tqdm(zip(code,docstring)):\n",
    "  codeToken.append(' '.join(tokenize_code(singleCode)))\n",
    "  docToken.append(' '.join(tokenize_docstring(singleDoc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b6d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_54834/2253202713.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['code token'] = codeToken\n",
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_54834/2253202713.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['doc token'] = docToken\n"
     ]
    }
   ],
   "source": [
    "df_trn_sub['code token'] = codeToken\n",
    "df_trn_sub['doc token'] = docToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d368f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 5610.78it/s]\n",
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_54834/49740048.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['clean_code'] = clean_code_token\n"
     ]
    }
   ],
   "source": [
    "#Clean Code Token\n",
    "code_token = list(df_trn_sub['code_tokens'].values)\n",
    "doc_token = list(df_trn_sub['doc token'].values)\n",
    "code_token_list = []\n",
    "doc_token_list = []\n",
    "for code,doc in tqdm(zip(code_token,doc_token)):\n",
    "    code_token_list.append(' '.join(code))\n",
    "    doc_token_list.append(' '.join(doc))\n",
    "\n",
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_idf = pd.DataFrame()\n",
    "df_idf['text'] = code_token_list\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "df_idf['doc text'] = doc_token_list\n",
    "df_idf['doc text'] = df_idf['doc text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "clean_code = list(df_idf['text'].values)\n",
    "clean_doc = list(df_idf['doc text'].values)\n",
    "clean_code_token = []\n",
    "for code,doc in zip(clean_code,clean_doc):\n",
    "  clean_code_token.append(code.split(' ')+doc.split(' '))\n",
    "df_trn_sub['clean_code'] = clean_code_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4f572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>docstring</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "      <th>code token</th>\n",
       "      <th>doc token</th>\n",
       "      <th>clean_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifi...</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "      <td>def train train_dir model_save_path None n_nei...</td>\n",
       "      <td>trains a k - nearest neighbors classifier for ...</td>\n",
       "      <td>[def, train, train_dir, model_save_path, none,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a...</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "      <td>def predict X_img_path knn_clf None model_path...</td>\n",
       "      <td>recognizes faces in given image using a traine...</td>\n",
       "      <td>[def, predict, x_img_path, knn_clf, none, mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visua...</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "      <td>def show_prediction_labels_on_image img_path p...</td>\n",
       "      <td>shows the face recognition results visually . ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, img_pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "      <td>def _rect_to_css rect Convert a dlib rect obje...</td>\n",
       "      <td>convert a dlib ' rect ' object to a plain tupl...</td>\n",
       "      <td>[def, _rect_to_css, rect, return, rect, top, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bott...</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "      <td>def _trim_css_to_bounds css image_shape Make s...</td>\n",
       "      <td>make sure a tuple in ( top , right , bottom , ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, css, image_shape, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                           docstring  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                                         code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                                    docstring_tokens  \\\n",
       "0  [Trains, a, k, -, nearest, neighbors, classifi...   \n",
       "1  [Recognizes, faces, in, given, image, using, a...   \n",
       "2  [Shows, the, face, recognition, results, visua...   \n",
       "3  [Convert, a, dlib, rect, object, to, a, plain,...   \n",
       "4  [Make, sure, a, tuple, in, (, top, right, bott...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/ageitgey/face_recognition/b...   \n",
       "1  https://github.com/ageitgey/face_recognition/b...   \n",
       "2  https://github.com/ageitgey/face_recognition/b...   \n",
       "3  https://github.com/ageitgey/face_recognition/b...   \n",
       "4  https://github.com/ageitgey/face_recognition/b...   \n",
       "\n",
       "                                          code token  \\\n",
       "0  def train train_dir model_save_path None n_nei...   \n",
       "1  def predict X_img_path knn_clf None model_path...   \n",
       "2  def show_prediction_labels_on_image img_path p...   \n",
       "3  def _rect_to_css rect Convert a dlib rect obje...   \n",
       "4  def _trim_css_to_bounds css image_shape Make s...   \n",
       "\n",
       "                                           doc token  \\\n",
       "0  trains a k - nearest neighbors classifier for ...   \n",
       "1  recognizes faces in given image using a traine...   \n",
       "2  shows the face recognition results visually . ...   \n",
       "3  convert a dlib ' rect ' object to a plain tupl...   \n",
       "4  make sure a tuple in ( top , right , bottom , ...   \n",
       "\n",
       "                                          clean_code  \n",
       "0  [def, train, train_dir, model_save_path, none,...  \n",
       "1  [def, predict, x_img_path, knn_clf, none, mode...  \n",
       "2  [def, show_prediction_labels_on_image, img_pat...  \n",
       "3  [def, _rect_to_css, rect, return, rect, top, r...  \n",
       "4  [def, _trim_css_to_bounds, css, image_shape, r...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1455dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Original Tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "data_corpus = list(df_trn_sub.clean_code.values)\n",
    "document_corpus = list(df_trn_sub.docstring.values)\n",
    "buffer = []\n",
    "for data in data_corpus:buffer.append(' '.join(data))\n",
    "vocabulary=vectorizer.fit(buffer)\n",
    "X= vectorizer.transform(buffer)\n",
    "# print('Code Tokens : ',vocabulary.get_feature_names())\n",
    "#print('Word Embeddings : ',X.toarray())\n",
    "baseData = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cad26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22176\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import ndcg_score\n",
    "from tqdm import tqdm\n",
    "testDocstring = list(df_tst.docstring.values)\n",
    "print(len(testDocstring))\n",
    "filteredDocstring = []\n",
    "for doc in testDocstring:\n",
    "    buffer = doc.split(' ')\n",
    "#   if len(buffer) < 10:filteredDocstring.append(doc)\n",
    "    filteredDocstring.append(doc)\n",
    "filteredDocstring = filteredDocstring[:400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5ba9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:01, 352.99it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "closest_doc_indexes = {}\n",
    "testingVector = vectorizer.transform(filteredDocstring)\n",
    "doctrainingVector = vectorizer.transform(document_corpus)\n",
    "for index, test_doc_embd in tqdm(enumerate(testingVector)):\n",
    "  test_doc_embd = np.reshape(test_doc_embd,(1,-1))\n",
    "  similarities = cosine_similarity(test_doc_embd,doctrainingVector)[0]\n",
    "  \n",
    "  most_similar_train_doc = np.argmax(similarities)\n",
    "  closest_doc_indexes[index] = most_similar_train_doc\n",
    "\n",
    "#print(closest_doc_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e9cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 400/400 [48:29<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = []\n",
    "ndcga = []\n",
    "mrr = []\n",
    "for doc in tqdm(filteredDocstring):\n",
    "    testingString = [doc]\n",
    "    testingVector = vectorizer.transform(testingString)\n",
    "    testingVector = testingVector.toarray()\n",
    "    distances = distance.cdist(testingVector, baseData, \"cosine\")[0]\n",
    "    min_index = np.argmin(distances)\n",
    "    min_distance = distances[min_index]\n",
    "    max_similarity = 1 - min_distance\n",
    "    result.append(max_similarity)\n",
    "    ndcga.append((ndcg_score(np.asarray(testingVector), np.asarray([baseData[min_index]]))))\n",
    "    index = filteredDocstring.index(doc)\n",
    "    closest = closest_doc_indexes[index]\n",
    "    best = np.argsort(distances)[:50]\n",
    "    \n",
    "    if closest in best:\n",
    "      best = list(best)\n",
    "      mrr.append(1/(best.index(closest)+1))\n",
    "    else:\n",
    "      mrr.append(0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59cd8883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543236839661495\n",
      "0.3966358238222773\n",
      "0.0224011853126206\n"
     ]
    }
   ],
   "source": [
    "result = [x for x in result if str(x) != 'nan']\n",
    "\n",
    "print('NDCGA Results : ',sum(ndcga)/len(ndcga))\n",
    "print('Similarity Average : ',sum(result)/len(result))\n",
    "print('Mean Reciprocal Rank :  ',sum(mrr)/len(mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cb26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
