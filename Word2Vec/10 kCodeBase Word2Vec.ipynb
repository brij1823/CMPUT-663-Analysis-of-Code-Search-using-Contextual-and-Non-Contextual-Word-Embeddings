{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0764944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing python libraries\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import astor\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# #pip install nmslib\n",
    "#import nmslib\n",
    "import numpy\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "79f27540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_sm\n",
    "EN = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "48915798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the database\n",
    "# ! wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
    "# ! unzip python.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a26d1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('.')\n",
    "#collapse_show\n",
    "def jsonl_list_to_dataframe(file_list, columns=None):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f,\n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "\n",
    "def get_dfs(path):\n",
    "    \"\"\"Grabs the different data splits and converts them into dataframes\"\"\"\n",
    "    dfs = []\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        files = sorted((path/split).glob(\"**/*.gz\"))\n",
    "        df = jsonl_list_to_dataframe(files, [\"code\", \"docstring\",\"code_tokens\",\"docstring_tokens\",\"url\"])\n",
    "        dfs.append(df)\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "\n",
    "def tokenize_docstring(text):\n",
    "    \"Apply tokenization using spacy to docstrings.\"\n",
    "    tokens = EN.tokenizer(text)\n",
    "    return [token.text.lower() for token in tokens if not token.is_space]\n",
    "\n",
    "\n",
    "def tokenize_code(text):\n",
    "    \"A very basic procedure for tokenizing code strings.\"\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "\n",
    "df_trn, df_val, df_tst = get_dfs(path/\"python/final/jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d2a5bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.to_csv('Training.csv')\n",
    "df_val.to_csv('Validation.csv')\n",
    "df_tst.to_csv('Testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c3f87b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412178, 5)\n",
      "46934\n"
     ]
    }
   ],
   "source": [
    "print(df_trn.shape)\n",
    "buff = list(df_trn.docstring.values)\n",
    "maxima = -1\n",
    "for doc in buff : \n",
    "    maxima = max(maxima,len(doc))\n",
    "print(maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8727baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n"
     ]
    }
   ],
   "source": [
    "#Subsample\n",
    "df_trn_sub = df_trn[:10000]\n",
    "print(df_trn_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a22ebc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstring = list(df_trn_sub['docstring'].values)\n",
    "code = list(df_trn_sub['code'].values)\n",
    "#print(code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ecfad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 3290.20it/s]\n"
     ]
    }
   ],
   "source": [
    "codeToken = []\n",
    "docToken = []\n",
    "\n",
    "for singleCode,singleDoc in tqdm(zip(code,docstring)):\n",
    "  codeToken.append(' '.join(tokenize_code(singleCode)))\n",
    "  docToken.append(' '.join(tokenize_docstring(singleDoc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f1f2a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_13602/2253202713.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['code token'] = codeToken\n",
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_13602/2253202713.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['doc token'] = docToken\n"
     ]
    }
   ],
   "source": [
    "df_trn_sub['code token'] = codeToken\n",
    "df_trn_sub['doc token'] = docToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3416f8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/nlrr4t_x3j5_jvwwktffc3j00000gn/T/ipykernel_13602/2655236840.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trn_sub['clean_code'] = clean_code_token\n"
     ]
    }
   ],
   "source": [
    "#Clean Code Token\n",
    "code_token = list(df_trn_sub['code_tokens'].values)\n",
    "code_token_list = []\n",
    "for code in code_token:\n",
    "  code_token_list.append(' '.join(code))\n",
    "\n",
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_idf = pd.DataFrame()\n",
    "df_idf['text'] = code_token_list\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "clean_code = list(df_idf['text'].values)\n",
    "clean_code_token = []\n",
    "for code in clean_code:\n",
    "  clean_code_token.append(code.split(' '))\n",
    "df_trn_sub['clean_code'] = clean_code_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76040ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Original Tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "data_corpus = list(df_trn_sub.clean_code.values)\n",
    "document_corpus = list(df_trn_sub.docstring.values)\n",
    "buffer = []\n",
    "for data in data_corpus:buffer.append(' '.join(data))\n",
    "vocabulary=vectorizer.fit(buffer)\n",
    "X= vectorizer.transform(buffer)\n",
    "# print('Code Tokens : ',vocabulary.get_feature_names())\n",
    "#print('Word Embeddings : ',X.toarray())\n",
    "baseData = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09838019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #pip install nmslib\n",
    "# import nmslib\n",
    "# # import numpy\n",
    "\n",
    "# testingString = [\"Inputs an expression which calculates to a list of rows.\"]\n",
    "# testingVector = vectorizer.transform(testingString)\n",
    "# testingVector = testingVector.toarray()\n",
    "# index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "# index.addDataPointBatch(baseData)\n",
    "# index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "# ids, distances = index.knnQuery(testingVector, k=10)\n",
    "# print(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5483bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import spatial\n",
    "# import heapq\n",
    "# from numpy import dot\n",
    "# from numpy.linalg import norm\n",
    "# from scipy.spatial import distance\n",
    "# testingString = [\"Inputs an expression which calculates to a list of rows.\"]\n",
    "# testingVector = vectorizer.transform(testingString)\n",
    "# testingVector = testingVector.toarray()\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.spatial import distance\n",
    "\n",
    "# distances = distance.cdist(testingVector, baseData, \"cosine\")[0]\n",
    "# min_index = np.argmin(distances)\n",
    "# min_distance = distances[min_index]\n",
    "# max_similarity = 1 - min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "721a1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87fb7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(document_corpus[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4fbf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(min_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a7ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d0818cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22176\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import ndcg_score\n",
    "from tqdm import tqdm\n",
    "testDocstring = list(df_tst.docstring.values)\n",
    "print(len(testDocstring))\n",
    "filteredDocstring = []\n",
    "for doc in testDocstring:\n",
    "    buffer = doc.split(' ')\n",
    "#   if len(buffer) < 10:filteredDocstring.append(doc)\n",
    "    filteredDocstring.append(doc)\n",
    "filteredDocstring = filteredDocstring[:400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa54e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:01, 396.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "closest_doc_indexes = {}\n",
    "testingVector = vectorizer.transform(filteredDocstring)\n",
    "doctrainingVector = vectorizer.transform(document_corpus)\n",
    "for index, test_doc_embd in tqdm(enumerate(testingVector)):\n",
    "  test_doc_embd = np.reshape(test_doc_embd,(1,-1))\n",
    "  similarities = cosine_similarity(test_doc_embd,doctrainingVector)[0]\n",
    "  \n",
    "  most_similar_train_doc = np.argmax(similarities)\n",
    "  closest_doc_indexes[index] = most_similar_train_doc\n",
    "\n",
    "#print(closest_doc_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "357c9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 400/400 [3:05:53<00:00, 27.88s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = []\n",
    "ndcga = []\n",
    "mrr = []\n",
    "for doc in tqdm(filteredDocstring):\n",
    "    testingString = [doc]\n",
    "    testingVector = vectorizer.transform(testingString)\n",
    "    testingVector = testingVector.toarray()\n",
    "    distances = distance.cdist(testingVector, baseData, \"cosine\")[0]\n",
    "    min_index = np.argmin(distances)\n",
    "    min_distance = distances[min_index]\n",
    "    max_similarity = 1 - min_distance\n",
    "    result.append(max_similarity)\n",
    "    ndcga.append((ndcg_score(np.asarray(testingVector), np.asarray([baseData[min_index]]))))\n",
    "    index = filteredDocstring.index(doc)\n",
    "    closest = closest_doc_indexes[index]\n",
    "    best = np.argsort(distances)[:50]\n",
    "    \n",
    "    if closest in best:\n",
    "      best = list(best)\n",
    "      mrr.append(1/(best.index(closest)+1))\n",
    "    else:\n",
    "      mrr.append(0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c707c3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5665437035612304\n",
      "0.42536924488795236\n",
      "0.03638729350588287\n"
     ]
    }
   ],
   "source": [
    "result = [x for x in result if str(x) != 'nan']\n",
    "\n",
    "print('NDCGA Results : ',sum(ndcga)/len(ndcga))\n",
    "print('Similarity Average : ',sum(result)/len(result))\n",
    "print('Mean Reciprocal Rank :  ',sum(mrr)/len(mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4460e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
